{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "\n",
    "import scipy \n",
    "from scipy import optimize\n",
    "import scipy.signal as signal \n",
    "import sys\n",
    "\n",
    "    \n",
    "sys.path.append('../../dsmuc/')\n",
    "from dsmuc.custom import detect_peaks\n",
    "import dsmuc.io as io\n",
    "import dsmuc.preprocessing as pp\n",
    "import dsmuc.features as ff\n",
    "import dsmuc.custom as cs\n",
    "\n",
    "\n",
    "import pytz\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from io import StringIO\n",
    "from azure.storage.blob import AppendBlobService\n",
    "from azure.storage.blob import BlockBlobService\n",
    "import requests\n",
    "import json\n",
    "\n",
    "label_dict = {1:'walking',\n",
    "             2:'walking upstairs',\n",
    "             3:'walking downstairs',\n",
    "             4:'sitting',\n",
    "             5:'standing',\n",
    "             6:'laying',\n",
    "             7:'unknown'}\n",
    "\n",
    "\n",
    "download_dir =  \"../../data/G9_data/Downloaded\"\n",
    "account_name='watchstorage'\n",
    "account_key='TJWcjsCs4aK9Xorw4DIAZGvKz0AFb2kvgSh49t+3nADR2usZ1ED14GLBQ/klJsSSrKykxu0ghCXn46+0bv2J8Q=='\n",
    "container_name_ = 'jnj'\n",
    "\n",
    "# Model saved\n",
    "filename = 'finalized_model.sav'\n",
    "logreg = pickle.load(open(filename, 'rb'), encoding = 'iso-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_str(t):\n",
    "    t_woM = t.replace(microsecond=0)\n",
    "    dt64 = np.datetime64(t_woM)\n",
    "    a = dt64.astype('datetime64[s]')\n",
    "    \n",
    "    return np.datetime_as_string(a)+\"Z\"\n",
    "def f(x):\n",
    "    u, c = np.unique(x['predictions'].values, return_counts=True)\n",
    "    outcome = u[np.argmax(c)]\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>blobname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2018-07-06</td>\n",
       "      <td>2018-07-06/873240569_e1bee96363d842628de06b604...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                           blobname\n",
       "120  2018-07-06  2018-07-06/873240569_e1bee96363d842628de06b604..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "#### READ DATA ###\n",
    "##################\n",
    "day_now=0\n",
    "day_before=1\n",
    "\n",
    "account_name='watchstorage'\n",
    "account_key='TJWcjsCs4aK9Xorw4DIAZGvKz0AFb2kvgSh49t+3nADR2usZ1ED14GLBQ/klJsSSrKykxu0ghCXn46+0bv2J8Q=='\n",
    "container_name_ = 'jnj'\n",
    "\n",
    "blob_service = BlockBlobService(account_name=account_name, account_key = account_key)\n",
    "\n",
    "\n",
    "blobs = [];blob_date = []\n",
    "generator = blob_service.list_blobs(container_name_)\n",
    "for blob in generator:\n",
    "    blobs.append(blob.name)\n",
    "    blob_date.append(blob.name[:10])\n",
    "blob_table = pd.DataFrame()\n",
    "blob_table['date'] = blob_date\n",
    "blob_table['blobname'] = blobs    \n",
    "today = date.today().strftime('%Y-%m-%d')\n",
    "yesterday = (date.today() - timedelta(3)).strftime('%Y-%m-%d')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_table = blob_table[(blob_table['date']==yesterday)|(blob_table['date']==today)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ DATA FRAMES SIZE : 677376\n",
      "CPU times: user 2.34 s, sys: 182 ms, total: 2.53 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if blob_table.shape[0]>0:\n",
    "    blob_df = pd.DataFrame()\n",
    "    for blobname in blob_table['blobname']:\n",
    "        blob_Class = blob_service.get_blob_to_text(container_name=container_name_, blob_name = blobname)\n",
    "        blob_String =blob_Class.content\n",
    "        \n",
    "        for chunk in pd.read_csv(StringIO(blob_String), chunksize=10000):\n",
    "            blob_df = blob_df.append(chunk)\n",
    "\n",
    "    print(\"READ DATA FRAMES SIZE :\",blob_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['watch-sensor-356969030313411', 'watch-sensor-356969030312934'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_df['id'].unique()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watch  watch-sensor-356969030313411  is being processed\n",
      "Extracting interested sensor data...\n",
      "READ DATA FRAMES SIZE AFTER CLEANING : 37552\n",
      "doing time: 2018-07-06 16:00:00  -  2018-07-06 16:05:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/dsmuc/custom/__init__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['date'] = pd.to_datetime(df[unix_col],unit=unit)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:14: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  \n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:17: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-45c1712c1f70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mout_ser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwhole_window_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mdf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_ser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;31m## Send predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "feature_list =  ['aoa','ate','apf','rms','std','minimax','cor','mean','min','max']\n",
    "preserved_features=['start']\n",
    "\n",
    "\n",
    "for watch_id in blob_df['id'].unique()[::-1]:\n",
    "    print(\"Watch \", watch_id,\" is being processed\" )\n",
    "    df_temp = io.read_g9(blob_df[blob_df['id']==watch_id], sort=False)\n",
    "    df_temp = df_temp.drop_duplicates(keep='last')[::2].sort_index()\n",
    "    print(\"READ DATA FRAMES SIZE AFTER CLEANING :\",df_temp.shape[0])\n",
    "\n",
    "\n",
    "    # Time to do analysis is specified\n",
    "    start = yesterday + 'T16:00:00.0000Z'\n",
    "    start_temp = np.datetime64(start)\n",
    "    t = pd.Timestamp(start_temp)\n",
    "    end = today + 'T16:00:00.0000Z'\n",
    "    end_temp = np.datetime64(end)\n",
    "    end_time = pd.Timestamp(end_temp)\n",
    "\n",
    "    # Initialize \n",
    "    whole_window_size = timedelta(minutes = 5)\n",
    "    window_size = timedelta(seconds=2)\n",
    "    window_slide = timedelta(seconds=1)\n",
    "    samples_count = []\n",
    "    a = 0\n",
    "    df_out = pd.DataFrame()\n",
    "    t_start_list = []\n",
    "    t_end_list = []\n",
    "    outcome_list = []\n",
    "    while (t + whole_window_size < end_time):\n",
    "        label_list = []\n",
    "        increment = 0\n",
    "        DF = pd.DataFrame()\n",
    "        t_end5min= t + whole_window_size \n",
    "        print(\"doing time:\",t, ' - ', t_end5min)\n",
    "        t_start_list.append(time_to_str(t))\n",
    "        t_end_list.append(time_to_str(t_end5min))\n",
    "        if df_temp.between_time(t.to_pydatetime().time(), t_end5min.to_pydatetime().time()\\\n",
    "                                           ,include_start=True, include_end=False).shape[0] >= 10:\n",
    "\n",
    "\n",
    "            while(t+window_slide< t_end5min):\n",
    "                t_end = t + window_size\n",
    "                snippet_df = df_temp.between_time(t.to_pydatetime().time(), t_end.to_pydatetime().time()\n",
    "                                               ,include_start=True, include_end=False)\n",
    "                if snippet_df.shape[0]>= 20:\n",
    "                    increment +=1\n",
    "                    ser = ff.extract_features(snippet_df, index=increment, feature_list=feature_list ,\\\n",
    "                                preserved_features=preserved_features)\n",
    "                    DF = DF.append(ser)\n",
    "                t = t_end\n",
    "        else:\n",
    "            t = t_end5min\n",
    "\n",
    "        if DF.shape[0]<=11:\n",
    "            outcome = 7.0\n",
    "        else:\n",
    "            df_X = DF.set_index(pd.DatetimeIndex(DF['start'])).drop('start' ,axis =1)\n",
    "            del DF \n",
    "            df_X.fillna(df_X.mean().fillna(0), inplace=True)\n",
    "            X_test = df_X.values\n",
    "            y_pred = logreg.predict(X_test)                \n",
    "            u, c = np.unique(y_pred, return_counts=True)\n",
    "            outcome = u[np.argmax(c)]\n",
    "        outcome_list.append(label_dict[int(outcome)])\n",
    "        out_ser = pd.Series(outcome,name=(t-whole_window_size, t) )\n",
    "        df_out = df_out.append(out_ser)\n",
    "        plt.plot(list(range(df_out.shape[0])), df_out[0], \"*\")\n",
    "        ## Send predictions \n",
    "    plt.show()   \n",
    "    dict_list = []\n",
    "    for i in range(len(outcome_list)):\n",
    "        payload_dict = {'address':watch_id.split(\"-\")[2],\n",
    "             'starttime':t_start_list[i],\n",
    "             'endtime':t_end_list[i],\n",
    "             'tasklocation':'Activity',\n",
    "             'taskname':outcome_list[i],\n",
    "             'name':outcome_list[i],\n",
    "             'value':1}\n",
    "        dict_list.append(payload_dict)\n",
    "    payload = json.dumps(dict_list)\n",
    "    url = \"https://colife-dashboard.silverline.mobi/uploadActivityLabelForSmartWatch\"\n",
    "    headers = {\n",
    "        'content-type': \"application/json\",\n",
    "        'cache-control': \"no-cache\",\n",
    "        'postman-token': \"87b2b04f-175f-4a9b-f2c8-bf31de2cae7d\"\n",
    "        }\n",
    "\n",
    "    response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "    print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool as ThreadPool \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(a):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = [1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 6.05 ms, total: 6.05 ms\n",
      "Wall time: 9.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pool = ThreadPool(7) \n",
    "results = pool.map(my_function, my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.13 ms, total: 1.13 ms\n",
      "Wall time: 2.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "for item in my_array:\n",
    "    results.append(my_function(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
