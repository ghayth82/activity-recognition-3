{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "bad magic number in 'detect_peaks': b'\\x03\\xf3\\r\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ae6323eaa007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../colife_activity_recognition/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetect_peaks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect_peaks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"darkgrid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: bad magic number in 'detect_peaks': b'\\x03\\xf3\\r\\n'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import scipy.signal as signal \n",
    "import scipy\n",
    "import datetime\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from detect_peaks import detect_peaks\n",
    "sns.set(style=\"darkgrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../../data/data_PD/PT18/\"\n",
    "\n",
    "interested_cols = [ 'AccX', 'AccY', 'AccZ', 'GyroX','GyroY', 'GyroZ']\n",
    "window_size = datetime.timedelta(seconds=2)\n",
    "window_slide = datetime.timedelta(seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = [ \n",
    "                        'mean',\n",
    "                        'min',\n",
    "                        'max',\n",
    "                        'range',\n",
    "                        'entropy_',\n",
    "                        'var',\n",
    "                        'kurtosis',\n",
    "                        'skew',\n",
    "                        'quantile25',\n",
    "                        'quantile50',\n",
    "                        'quantile75',\n",
    "                        'energy', \n",
    "                        'label',\n",
    "                        'frequency_features',\n",
    "                        'subject_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.mean(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_mean'\n",
    "    return var\n",
    "def min_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.min(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_min'\n",
    "    return var\n",
    "def max_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.max(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_max'\n",
    "    return var\n",
    "def range_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = (np.max(a)-np.min(a))\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_range'\n",
    "    return var\n",
    "def entropy_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        e =np.histogram(a)[0]\n",
    "        var_temp = scipy.stats.entropy(e/ np.sum(e))\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_entropy'\n",
    "    return var\n",
    "def var_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.var(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_var'\n",
    "    return var\n",
    "def kurtosis_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = scipy.stats.kurtosis(a, fisher=True)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_kurtosis'\n",
    "    return var\n",
    "def skewness_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = scipy.stats.skew(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_skew'\n",
    "    return var\n",
    "def quantile25_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.percentile(a,25)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_q25'\n",
    "    return var\n",
    "def quantile50_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.percentile(a,50)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_q50'\n",
    "    return var\n",
    "def quantile75_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.percentile(a,75)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_q75'\n",
    "    return var\n",
    "def energy_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.sum(np.mean(a**2)) \n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_energy'\n",
    "    return var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx\n",
    "def frequency_features(df):\n",
    "    list_= []\n",
    "    index_name = []\n",
    "    frequency_features_list = ['energy_total','energy_interested','max_total', 'max_interested']\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        f, psdX = signal.periodogram(a, fs=50, nfft = 256)\n",
    "        i_low = find_nearest(f,4.0)\n",
    "        i_high = find_nearest(f,7.0)\n",
    "\n",
    "        energy_total = np.sum(psdX) \n",
    "        energy_interested = np.sum(psdX[i_low : i_high + 1]) \n",
    "        max_total = np.max(psdX)\n",
    "        max_interested = np.max(psdX[i_low : i_high + 1])\n",
    "        var_temp = [energy_total, energy_interested, max_total, max_interested]\n",
    "        list_.extend(var_temp)\n",
    "        index_name.extend([col+'_'+x for x in frequency_features_list])\n",
    "    var = pd.Series(list_, index=index_name)\n",
    "    return var\n",
    "def average_over_axis(df):\n",
    "    aoa = df[interested_cols].mean(axis = 0)\n",
    "    aoa.index += '_aoa'\n",
    "    return aoa\n",
    "def average_time_elapse(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        mph = a.mean()\n",
    "        ind = detect_peaks(a, mph = mph, mpd=20, show=False)\n",
    "        list_.append(np.diff(ind).mean())\n",
    "    ate = pd.Series(list_, index=interested_cols)\n",
    "    ate.index += '_ate'\n",
    "    return ate\n",
    "def average_peak_freq(df):\n",
    "    list_f= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        mph = a.mean()\n",
    "        ind = detect_peaks(a, mph = mph, mpd=20, show=False)\n",
    "        list_f.append(len(ind)/a.shape[0])\n",
    "    apf = pd.Series(list_f, index=interested_cols)\n",
    "    apf.index += '_apf'\n",
    "    return apf\n",
    "def rms_func(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        rms_temp = np.sqrt(np.mean(a**2))\n",
    "        list_.append(rms_temp)\n",
    "    rms = pd.Series(list_, index=interested_cols)\n",
    "    rms.index += '_rms'\n",
    "    return rms\n",
    "def std_func(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        std_temp = np.std(a)\n",
    "        list_.append(std_temp)\n",
    "    std = pd.Series(list_, index=interested_cols)\n",
    "    std.index += '_std'\n",
    "    return std\n",
    "def minmax_func(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        minmax_temp = np.max(a)-np.min(a)\n",
    "        list_.append(minmax_temp)\n",
    "    minmax = pd.Series(list_, index=interested_cols)\n",
    "    minmax.index += '_minmax'\n",
    "    return minmax\n",
    "def cor_func(df):\n",
    "    a = df[interested_cols[:3]].corr()\n",
    "    b= df[interested_cols[3:]].corr()\n",
    "    indexes = ['CorAccXAccY','CorAccXAccZ','CorAccYAccZ', 'CorGyroXGyroY','CorGyroXGyroZ','CorGyroYGyroZ']\n",
    "    Cor = (a['AccX'][1:]).append(a['AccY'][2:]).append((b['GyroX'][1:]).append(b['GyroY'][2:]))\n",
    "    corr = pd.Series(Cor.values, indexes)\n",
    "    corr.index += '_corr'\n",
    "    return corr\n",
    "def label_(df):\n",
    "    return pd.Series(df['label'][0], index=['label'])\n",
    "def subject_id_(df):\n",
    "    return pd.Series(df['subject_id'][0], index=['subject_id'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_features(df, index, feature_list ):\n",
    "    \n",
    "    feature_func_dict = {\n",
    "                        'aoa':average_over_axis,\n",
    "                        'ate': average_time_elapse,\n",
    "                        'apf':average_peak_freq,\n",
    "                        'rms':rms_func,\n",
    "                        'std':std_func,\n",
    "                        'minimax':minmax_func,\n",
    "                        'cor':cor_func,\n",
    "                        'mean':mean_,\n",
    "                        'min':min_,\n",
    "                        'max':max_,\n",
    "                        'range':range_,\n",
    "                        'entropy_':entropy_,\n",
    "                        'var':var_,\n",
    "                        'kurtosis' : kurtosis_,\n",
    "                        'skew':skewness_,\n",
    "                        'quantile25':quantile25_,\n",
    "                        'quantile50':quantile50_,\n",
    "                        'quantile75':quantile75_,\n",
    "                        'energy':energy_,\n",
    "                        'frequency_features':frequency_features,\n",
    "                        'label':label_,\n",
    "                        'subject_id':subject_id_\n",
    "        }\n",
    "\n",
    "\n",
    "    ser_list = []\n",
    "    ser_list.append(pd.Series(str(index[0]),index=['start']))\n",
    "    ser_list.append(pd.Series(str(index[1]),index=['end']))\n",
    "    for x in feature_list:\n",
    "        ser_list.append(feature_func_dict[x](df))\n",
    "    ser = pd.concat(ser_list)\n",
    "    if type(index)!=str:\n",
    "        index = str(index)\n",
    "    ser.name = index\n",
    "    return ser\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''def get_all_features(df, index):\n",
    "    feature_list = ['subject_id', 'aoa', 'ate', 'apf', 'rms', 'std', 'minmax', 'cor', 'label']\n",
    "#     feature_func_dict = {'aoa':average_over_axis,\n",
    "#                         'ate': average_time_elapse,\n",
    "#                         'apf':average_peak_freq,\n",
    "#                         'rms':rms_func,\n",
    "#                         'std':std_func,\n",
    "#                         'minimax':minmax_func,\n",
    "#                         'cor':cor_func}\n",
    "    \n",
    "    aoa = average_over_axis(df)\n",
    "    ate = average_time_elapse(df)\n",
    "    apf = average_peak_freq(df)\n",
    "    rms = rms_func(df)\n",
    "    std = std_func(df)\n",
    "    minmax = minmax_func(df)\n",
    "    cor = cor_func(df)\n",
    "    subject_id = pd.Series(df['subject_id'][0], index=['subject_id'])\n",
    "    label = pd.Series(df['label'][0], index=['label'])\n",
    "    \n",
    "    ser_list = [pd.Series(str(index[0]),index=['start']),pd.Series(str(index[1]),index=['end']), subject_id, aoa, ate,apf, rms,std, minmax, cor, label]\n",
    "    ser = pd.concat(ser_list)\n",
    "    if type(index)!=str:\n",
    "        index = str(index)\n",
    "    ser.name = index\n",
    "    \n",
    "    return ser\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "def find_csv_filenames( path_to_dir, suffix=\".csv\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "window_size_seconds = 2\n",
    "window_slide_seconds = 1\n",
    "min_samples = 20\n",
    "save_to = '../../data/PT18_preprocessed_extra/'\n",
    "\n",
    "for file_name in find_csv_filenames(data_path):\n",
    "\n",
    "    window_size = datetime.timedelta(seconds=window_size_seconds)\n",
    "    window_slide = datetime.timedelta(seconds=window_slide_seconds)\n",
    "    try:\n",
    "    \n",
    "        df = pd.read_csv(data_path+file_name, index_col=0)\n",
    "\n",
    "        df['date_time'] = pd.to_datetime(df['time'],unit='ms')\n",
    "        df = df.set_index(pd.DatetimeIndex(df['date_time']))\n",
    "\n",
    "        df = df[['accelerometerX', 'accelerometerY', 'accelerometerZ', 'gyroscopeX',\n",
    "               'gyroscopeY', 'gyroscopeZ','label']]\n",
    "\n",
    "        df.columns = interested_cols + ['label']\n",
    "\n",
    "        df['subject_id'] = (file_name.split('.000')[1].split('.')[0])\n",
    "\n",
    "        df = df.sort_index(ascending = True)\n",
    "\n",
    "\n",
    "        df = df.sort_index(ascending = True)\n",
    "        ## Extract Segments\n",
    "\n",
    "\n",
    "        print('Extracting segments and saving file :', file_name)\n",
    "        samples_count = []\n",
    "        DF = pd.DataFrame()\n",
    "\n",
    "        t = df.index[0]\n",
    "        end_time = df.index[-1]\n",
    "        increment = 0\n",
    "        while(t + datetime.timedelta(seconds=1) < end_time):\n",
    "\n",
    "            t_end = t + window_size\n",
    "            sensor_data = df.between_time(t.to_pydatetime().time(), t_end.to_pydatetime().time()\n",
    "                                               ,include_start=True, include_end=False)\n",
    "            if sensor_data.shape[0]>= min_samples:\n",
    "                increment +=1\n",
    "                ser = get_all_features(sensor_data, index=(t, t_end), feature_list=feature_list)\n",
    "                DF = DF.append(ser, verify_integrity=True)\n",
    "\n",
    "            t = t+window_slide\n",
    "\n",
    "        DF.to_csv(save_to+file_name+'_preprocessed.csv', index=True)\n",
    "    except Exception:\n",
    "        print('file: '+file_name+' not readable')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
