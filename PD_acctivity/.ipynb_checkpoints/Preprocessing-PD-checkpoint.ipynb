{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import scipy.signal as signal \n",
    "import scipy\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from detect_peaks import detect_peaks\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "label_dict = {1:'walking',\n",
    "             0:'not_walking'}\n",
    "saveto = \"../../data/data_PD/snippets/\"\n",
    "label_folders = next(os.walk(saveto))[1]\n",
    "interested_cols = [ 'AccX', 'AccY', 'AccZ', 'GyroX','GyroY', 'GyroZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/data_PD/snippets/walking/1.csv\", index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03030303, 0.0530303 , 0.45454545, 0.23484848, 0.18939394,\n",
       "       0.01515152, 0.01515152, 0.        , 0.        , 0.00757576])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(df['AccX'])[0]/ np.sum(np.histogram(df['AccX'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.mean(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_mean'\n",
    "    return var\n",
    "def min_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.min(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_min'\n",
    "    return var\n",
    "def max_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.max(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_max'\n",
    "    return var\n",
    "def range_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = (np.max(a)-np.min(a))\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_range'\n",
    "    return var\n",
    "def entropy_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        e =np.histogram(a)[0]\n",
    "        var_temp = scipy.stats.entropy(e/ np.sum(e))\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_entropy'\n",
    "    return var\n",
    "def var_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.var(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_var'\n",
    "    return var\n",
    "def kurtosis_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = scipy.stats.kurtosis(a, fisher=True)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_kurtosis'\n",
    "    return var\n",
    "def skewness_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = scipy.stats.skew(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_skew'\n",
    "    return var\n",
    "def quantile25_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.percentile(a,25)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_q25'\n",
    "    return var\n",
    "def energy_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        rms_temp = np.sqrt(np.mean(a**2))\n",
    "        list_.append(rms_temp)\n",
    "    rms = pd.Series(list_, index=interested_cols)\n",
    "    rms.index += '_rms'\n",
    "    return rms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx\n",
    "def extract_energy_variables(f, psdX):\n",
    "    \n",
    "    i_low = find_nearest(f,4.0)\n",
    "    i_high = find_nearest(f,7.0)\n",
    "    \n",
    "    energy_total = np.sum(psdX) \n",
    "    energy_interested = np.sum(psdX[i_low : i_high + 1]) \n",
    "    max_total = np.max(psdX)\n",
    "    max_interested = np.max(psdX[i_low : i_high + 1])\n",
    "    return energy_total,energy_interested, max_total, max_interested\n",
    "def average_over_axis(df):\n",
    "    aoa = df[interested_cols].mean(axis = 0)\n",
    "    aoa.index += '_aoa'\n",
    "    return aoa\n",
    "def average_time_elapse(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        mph = a.mean()\n",
    "        ind = detect_peaks(a, mph = mph, mpd=20, show=False)\n",
    "        list_.append(np.diff(ind).mean())\n",
    "    ate = pd.Series(list_, index=interested_cols)\n",
    "    ate.index += '_ate'\n",
    "    return ate\n",
    "def average_peak_freq(df):\n",
    "    list_f= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        mph = a.mean()\n",
    "        ind = detect_peaks(a, mph = mph, mpd=20, show=False)\n",
    "        list_f.append(len(ind)/a.shape[0])\n",
    "    apf = pd.Series(list_f, index=interested_cols)\n",
    "    apf.index += '_apf'\n",
    "    return apf\n",
    "def rms_func(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        rms_temp = np.sqrt(np.mean(a**2))\n",
    "        list_.append(rms_temp)\n",
    "    rms = pd.Series(list_, index=interested_cols)\n",
    "    rms.index += '_rms'\n",
    "    return rms\n",
    "def std_func(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        std_temp = np.std(a)\n",
    "        list_.append(std_temp)\n",
    "    std = pd.Series(list_, index=interested_cols)\n",
    "    std.index += '_std'\n",
    "    return std\n",
    "def minmax_func(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        minmax_temp = np.max(a)-np.min(a)\n",
    "        list_.append(minmax_temp)\n",
    "    minmax = pd.Series(list_, index=interested_cols)\n",
    "    minmax.index += '_minmax'\n",
    "    return minmax\n",
    "def cor_func(df):\n",
    "    a = df[interested_cols[:3]].corr()\n",
    "    b= df[interested_cols[3:]].corr()\n",
    "    indexes = ['CorAccXAccY','CorAccXAccZ','CorAccYAccZ', 'CorGyroXGyroY','CorGyroXGyroZ','CorGyroYGyroZ']\n",
    "    Cor = (a['AccX'][1:]).append(a['AccY'][2:]).append((b['GyroX'][1:]).append(b['GyroY'][2:]))\n",
    "    corr = pd.Series(Cor.values, indexes)\n",
    "    corr.index += '_corr'\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_features(df, file):\n",
    "    feature_list = [ 'aoa', 'ate', 'apf', 'rms', 'std', 'minmax', 'cor', 'label']\n",
    "    feature_func_dict = ['aoa':average_over_axis,\n",
    "                        'ate': average_time_elapse,\n",
    "                        'apf':average_peak_freq,\n",
    "                        'rms':rms_func,\n",
    "                        'std':std_func,\n",
    "                        'minimax':minmax_func,\n",
    "                        'cor':cor_func]\n",
    "    aoa = average_over_axis(df)\n",
    "    ate = average_time_elapse(df)\n",
    "    apf = average_peak_freq(df)\n",
    "    rms = rms_func(df)\n",
    "    std = std_func(df)\n",
    "    minmax = minmax_func(df)\n",
    "    cor = cor_func(df)\n",
    "    label = pd.Series(df['label'][0], index=['label'])\n",
    "    ser_list = [aoa, ate,apf, rms,std, minmax, cor, label]\n",
    "    ser = pd.concat(ser_list)\n",
    "    ser.name = file\n",
    "    return ser\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started the process of :  ../../../../datadrive/data_PD/snippets/not_walking/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:24: RuntimeWarning: Mean of empty slice.\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished the process of :  ../../../../datadrive/data_PD/snippets/not_walking/\n",
      "Started the process of :  ../../../../datadrive/data_PD/snippets/walking/\n",
      "Finished the process of :  ../../../../datadrive/data_PD/snippets/walking/\n"
     ]
    }
   ],
   "source": [
    "DF = pd.DataFrame()\n",
    "for fol in label_folders:\n",
    "    folder = saveto+fol+'/'\n",
    "    print(\"Started the process of : \",folder )\n",
    "    for root,dirs,files in os.walk(folder):\n",
    "        for file_ in files:\n",
    "            if file_.endswith(\".csv\"):\n",
    "                df_temp = pd.read_csv(folder+file_)\n",
    "                ser = get_all_features(df_temp, file = fol+file_.split('.')[0])\n",
    "                ser = ser.round(4)\n",
    "                DF = DF.append(ser, verify_integrity=True)\n",
    "    \n",
    "    print(\"Finished the process of : \",folder )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF.to_csv('../../../data/data_PD/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, Pxx_den = signal.periodogram(df_la['AccX'], fs, nfft = 256)\n",
    "energy_total,energy_interested, max_total, max_interested =extract_energy_variables(f,Pxx_den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "                plt.semilogy(f, Pxx_den)\n",
    "                plt.xlabel('frequency [Hz]')\n",
    "                plt.ylabel('PSD [V**2/Hz]')\n",
    "                plt.ylim(1e-10, 1e+1)\n",
    "                plt.title(str(energy_total)+\" \"+str(energy_interested)+\" \"+ str(max_total)+\" \"+ str(max_interested))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../../../data/data_PD/preprocessed_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2c75d71b5a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../data/data_PD/preprocessed_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../../../data/data_PD/preprocessed_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv('../../../data/data_PD/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
